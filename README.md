# Machine-Learning:

1. Classification Algorithms:- Logistic Regression, SVM, Decision Tress, Random Forest Classification, XG-Boost, Naive Bayes, Kernal_SVM.
1. Regression Algorithms :- Linear Regression, SVR,Decision Tress, Random Forest Regression.<br/>
### Regression
| Regression Model | Pros | Cons |
| --- | --- | --- |
| **Linear Regression** | Works on any size of dataset, gives informations about relevance of features | The Linear Regression Assumptions |
| **Polynomial Regression** | Works on any size of dataset, works very well on non linear problems | Need to choose the right polynomial degree  for a good bias/variance tradeoff |
| **SVR** | Easily adaptable, works very well on nonlinear problems, not biased by outliers | Compulsory to apply feature scaling, not well known, more difficult to understand |
| **Decision Tree Regression** | Interpretability, no need for feature scaling, works on both linear / nonlinear problems | Poor results on too small datasets, overfitting can easily occur |
| **Random Forest Regression** | Powerful and accurate, good performance on many problems, including non linear | No interpretability, overfitting can easilyoccur, need to choose the number of trees |

1. Clustering Algorithms :-KMeans, Hierarchical(agglomerative) Clustering.<br/>
### Clustering

| Clustering Model | Pros | Cons |
| --- | --- | --- |
| **K-Means** | Simple to understand, easily adaptable,works well on small or large datasets, fast, efficient and performant | Need to choose the number of clusters |
| **Hierarchical Clustering** | The optimal number of clusters can be obtained by the model itself, practical visualisation with the dendrogram | Not appropriate for large datasets |




